\section{Preliminaries}
\label{sec:prelim}

%\subsection{Local distributed algorithms.}
%\input{prelim:model}

%\subsection{On security parameters, succinctness and efficient provers.}
%\input{prelim:secpars}
%\TODO{Should this be here?}

%\subsection{Common reference string (CRS) model}
%\input{prelim:crs}
%\TODO{Should this be here?}

\subsection{Recursively constructable hash families with local openings}
A hash family with local opening allows a sender to produce a short hash value of a long input (which we'll refer to as an input vector), and than locally open specific locations in the input. In \cite{merkle1989certified}, Merkle shows how to construct it from a collision-resistant hash family (CRH). The original construction by Merkle has some useful properties that we can properly define and use once opening the black-box and externalizing the underlying CRH. So, we first give here the definition of CRH for completeness and then proceed to define recursively constructable hash families with local openings ($\MT$).

\begin{definition}
    A hash family $\calH = (\calH.\Gen, \calH.\Hash)$ is collision resistant if there exists a negligible function $\negl$ such that for any poly-time adversary $\Adv$ the following holds:
    \begin{gather*}
        \prb{
        \calH.\Hash(hk, x_1) = \calH.\Hash(hk, x_2)
        }{
        \hk\leftarrow \calH.\Gen(1^\secpar) \\
        x_1, x_2 \leftarrow \Adv(\hk)}
    \end{gather*}
\end{definition}

\paragraph{$\MT$: Syntax.}
A recursively constructable hash family ($\MT$) with succinct local openings is defined with respect to a collision resistant hash family:
$$\calH = \calH.\Gen, \calH.\Hash$$
and consists of the following algorithms:
\begin{itemize}
    \item $\Gen(1^\secpar, 1^N
    )\to \hk$: a randomized algorithm that takes as input the security parameter $\secpar$ and the length $N$ of the vector to be hashed,
    and outputs a hash key $\hk$ = $\calH.\Gen(1^\secpar)$. \TODO{Decide how this work with $N$}
    \item $\Hash(\hk, x)\to \val$: a deterministic algorithm that takes a vector $x$ and a hash key $\hk$, and outputs a hash value $\val$.
    \item $\Open(\hk, x, i)\to b, \rho_i$: a deterministic algorithm that takes a hash key $\hk$, a vector $x$ and an index $i$, and outputs a bit $b$ and an opening $\rho_i$.
    \item $\Verify(\hk, \val, i, b, \rho ) \in \zo$: a verification algorithm that takes a hash key $\hk$, a value $\val$, an index $i$, a bit $b$, and an opening $\rho$, and outputs an acceptance bit.
\end{itemize}

\begin{definition} [Properties of $\MT$]\label{def:MT}
An $\MT$ $(\Gen, \Hash, \Open, \Verify)$ is required to satisfy:
\begin{itemize}
    \item \emph{Succinctness. } \TODO{}
    \item \emph{Opening completeness. } For any $\secpar \in \nat$, any $N \leq 2^\secpar$, any $x\in\zo^N$ and any index $i\in[N]$
    \begin{gather*}
        \prb{
        b= x_i \\
        \wedge ~\Verify(\hk, \val, i, b, \rho)
        }{
        \hk \leftarrow \Gen(1^\secpar, 1^N)
        )\\
        v \leftarrow \Hash(\hk, x) \\
        (b, \rho) = \Open(\hk, x, i) \\
        } = 1
    \end{gather*}
    \item \emph{Collision resistance w.r.t opening. } For any poly-size adversary $\Adv$ there exists a negligible function $\negl(Â·)$ such that for every $\secpar \in \nat$,
    \begin{gather*}
        \prb{
        \Verify(\hk, \val, i, 0, \rho_0 ) = 1 \\
        \wedge ~\Verify(\hk, \val, i, 1, \rho_1 ) = 1
        }{
        \hk \leftarrow \Gen(1^\secpar, 1^N
        ) \\
        \val, i, \rho_0, \rho_1 \leftarrow \Adv(\hk)
        } \leq \negl(\secpar)
    \end{gather*}
    %\item \emph{Global determinism w.r.t opening. } \TODO{Add N (in binary, not unary) to the hash value, and just double it when recursively constructing} For every (unbounded) adversary $\Adv$
    %\begin{gather*}
    %    \prb{
    %    \forall i\in[N] ~\Verify(\hk, \val_1, i, x_i, \rho_1^i ) = 1 \\
    %    \wedge ~\forall i\in[N] ~\Verify(\hk, \val_2, i, x_i, \rho_2^i ) = 1 \\
    %    \wedge ~\val_1 \neq \val_2
    %    }{
    %    \hk \leftarrow \Gen(1^\secpar%, 1^N
    %    ) \\
    %    \wedge ~ x, \val_1, \val_2, \set{\rho_1^i}_{i\in[N]}, \set{\rho_2^i}_{i\in[N]} \leftarrow \Adv(\hk)
    %    } = 0
    %\end{gather*}
    \item \emph{Recursive Constructability. }
    For every $\secpar\in\nat, N\leq 2^\secpar$, for every $\hk$ such that $\Pr[\hk = \Gen(1^\secpar, N)] > 0$, for every two vectors of the same length $x_1, x_2$, the following holds:
    \begin{itemize}
        \item $\Hash(\hk, x_1 || x_2) = \calH(\hk, \Hash(\hk, x_1), \Hash(\hk, x_2))$
        \item For $i\in[N]$, let:
        \begin{itemize}
            \item $b^1_i, \rho^1_i=\Open(\hk, x_1, i)$
            \item $b^2_i, \rho^2_i=\Open(\hk, x_2, i)$
        \end{itemize}
        So: 
        \begin{itemize}
            \item $\Open(\hk, x_1||x_2, i) = b^1_i, \Hash(\hk, x_2) || \rho^1_i$
            \item $\Open(\hk, x_1||x_2, N+i) = b^2_i, \Hash(\hk, x_1) || \rho^2_i$
        \end{itemize}
    \end{itemize}
    
\end{itemize}
\end{definition}

\subsection{SNARGs, SNARKs and RAM SNARGs}
A SNARG (or a SNARK) consists of the procedures:
\begin{itemize}
    \item $\Gen(1^\secpar, N)\to \crs$: a setup procedure that takes a security parameter $\secpar$ and an instance length $N$, and generates a $\crs$.
    \item $\Pro(\crs, x, w)\to \pi$: a proof generation algorithm that takes the $\crs$, an instance $x\in\zo^N$, and a witness $w$ of length $\poly(\ell)$, 	and produces a proof $\pi$.
    \item $\Ver(\crs, x, \pi)\to \set{0,1}$: a verification algorithm that takes the $\crs$, an instance $x\in\zo^N$, and a proof $\pi$, and returns an acceptance bit.
\end{itemize}
\begin{definition} [Succinct Non-Interactive Argument]\label{def:snarg}
Let $\Lan$ be a language with a verifying machine $M$ such that $x \in \Lan$ iff $\exists w: M(x,w)=1$, and let $\secpar$ be a security parameter. $(\Gen, \Ver, \Pro)$ is a \emph{SNARG $\Lan$}
if it satisfies the following properties.
\begin{itemize}
    \item \emph{Succinctness and Efficiency.} The length of the proof $\pi$ produced by $\Pro$ is $\poly(\lambda, \log \ell)$.
    $\Ver$ runs in time $\poly(\lambda, |\pi|) = \poly(\lambda, \log n)$
    and $\Pro$ runs in time $\poly(\lambda, n)$.
    \item \emph{Completeness. } For every $x$ and $w$ such that $M(x,w)=1$,
    \begin{gather*}
        \prob{}
        { 
        \begin{array}{ll}
        \Ver(\crs, x, \pi) = 1
        \end{array}
        \middle\vert
        \begin{array}{ll}
        \var{\crs} \leftarrow \Gen(1^\secpar, \ell) \\
        \pi \leftarrow \Pro(\var{\crs}, x, w) \\
        \end{array}
        } = 1
	.
    \end{gather*}
    \item \emph{(Addaptive) Soundness. }
    For any poly-size prover $\Pro^*$, there exists a negligible function $\negl(\cdot)$ such that,
    \begin{gather*}
        \prb{
        \Ver(\crs, x, \pi) = 1 \\
        \wedge ~ x\notin \Lan
        }{
        \crs \leftarrow \Gen(1^\secpar, 1^N) \\
        x, \pi \leftarrow \Pro^*(\crs)
        } \leq \negl(\secpar)
    \end{gather*}
\end{itemize}
We say $(\Gen, \Pro, \Ver)$ is a succinct non-interactive argument of knowledge (SNARK), if additionally,\footnote{This actually implies soundness and can replace it.} the following holds:
\begin{itemize}
    \item \emph{Argument of Knowledge.} For any efficient prover $\Pro^*$, there exists an efficient extraction algorithm, $\Ext_{\Pro^*}$, and a negligible function $\epsilon(\cdot)$, such that,
    \begin{gather*}
        \prob{}
        {
        \begin{array}{ll}
        \Ver(\var{\crs}, x, \pi^*) = 1 \\
        \wedge\ M(x,w)\neq 1
        \end{array}
        \middle\vert
        \begin{array}{ll}
        \var{\crs} \leftarrow \Gen(1^\secpar, \ell) \\
        (x, \pi^*) \leftarrow \Pro^*(\var{\crs}) \\
        w\leftarrow \Ext_{\Pro^*}(\var{\crs}, x)
        \end{array}
        } \leq \epsilon(\secpar)
	.
    \end{gather*}
\end{itemize}
\end{definition}
%Note that the prover $\Pro^*$ \emph{chooses} the statement $x$ that it would like to prove, and it does so after seeing the $\crs$. This is called \emph{adaptive soundness}, and it is stronger than asserting that there does not exist any $x \not \in \calL$ that the prover can cause the verifier to accept with non-negligible probability (if there existed such an $x$, we could ``hard-wire'' it into the prover in the adaptive definition).

\TODO{Add theorems citations for existence of SNARKs for NP and SNARGs for P from respective assumptions}

\subsection{RAM SNARGs / BARGs}
\TODO{Decide to which of these we should refer}
A RAM SNARG allows a  prover to prove to a verifier that $M(x) = 1$ for some machine $M$, where the verifier does not have access to $x$ itself but to an \emph{digest} of it, which is much shorter. We use RAM SNARGs that are defined w.r.t a hash family with local openings
It has a similar syntax to that of a SNARG, with the following differences:
\begin{itemize}
    \item 
\end{itemize}